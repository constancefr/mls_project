{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(fn, *args, func_type = \"cupy\", n=1000, device='cuda'):    \n",
    "    # Warm-up\n",
    "    for _ in range(10):\n",
    "        _ = fn(*args)\n",
    "    if func_type == \"torch\" and device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    if func_type==\"cupy\":\n",
    "        cp.cuda.stream.get_current_stream().synchronize()\n",
    "    # Timed run\n",
    "    start = time.time()\n",
    "    for _ in range(n):\n",
    "        _ = fn(*args)\n",
    "    end = time.time()\n",
    "    if func_type == \"torch\" and device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    if func_type==\"cupy\":\n",
    "        cp.cuda.stream.get_current_stream().synchronize()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def torch_add(a,b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_add =r\"\"\"                  \n",
    "extern \"C\" __global__\n",
    "void vector_add(const float* a, const float* b, float* c, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n) {\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "add_kernel=cp.RawKernel(vec_add, 'vector_add')\n",
    "def cupy_add(a,b):\n",
    "        n = a.shape[0]\n",
    "        threads_per_block = min(n, 1024)  # Max threads per block\n",
    "        blocks_per_grid = 1  # Single block\n",
    "        y = cp.empty_like(a)  # Pre-allocate output\n",
    "        add_kernel((blocks_per_grid,), (threads_per_block,), (a, b, y, n))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(fn1, fn2):\n",
    "    for n in [64,16384,65536,262144,4194304]:\n",
    "        print(\"----------\")\n",
    "        print(\"dim =\", n)\n",
    "        x1= cp.arange(n).astype(cp.float32)\n",
    "        x2 = cp.arange(n).astype(cp.float32)\n",
    "        cupy_time = benchmark(fn1,x1,x2)\n",
    "        print(\"cupy:\",cupy_time)\n",
    "        del x1\n",
    "        del x2\n",
    "        x1= torch.arange(n, device=\"cuda\", dtype=torch.float32)\n",
    "        x2= torch.arange(n, device=\"cuda\", dtype=torch.float32)\n",
    "        torch_time = benchmark(fn2, x1,x2, func_type=\"torch\")\n",
    "        print(\"torch:\", torch_time)\n",
    "        print(\"Speedup:\", torch_time/cupy_time)\n",
    "        del x1\n",
    "        del x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "dim = 64\n",
      "cupy: 0.025129318237304688\n",
      "torch: 0.015166282653808594\n",
      "Speedup: 0.6035294117647059\n",
      "----------\n",
      "dim = 16384\n",
      "cupy: 0.026528358459472656\n",
      "torch: 0.01592850685119629\n",
      "Speedup: 0.6004331883380667\n",
      "----------\n",
      "dim = 65536\n",
      "cupy: 0.02687692642211914\n",
      "torch: 0.01564788818359375\n",
      "Speedup: 0.5822052692273574\n",
      "----------\n",
      "dim = 262144\n",
      "cupy: 0.03642463684082031\n",
      "torch: 0.015377521514892578\n",
      "Speedup: 0.42217363983871814\n",
      "----------\n",
      "dim = 4194304\n",
      "cupy: 0.037996530532836914\n",
      "torch: 0.026365995407104492\n",
      "Speedup: 0.6939053391813966\n"
     ]
    }
   ],
   "source": [
    "compare(cupy_add, torch_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_code = \"\"\"\n",
    "extern \"C\" __global__\n",
    "void dot_product(const float* x, const float* y, float* result, int n) {\n",
    "    __shared__ float shared_mem[256];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    float temp = 0;\n",
    "    while (i < n) {\n",
    "        temp += x[i] * y[i];\n",
    "        i += blockDim.x * gridDim.x;\n",
    "    }\n",
    "    \n",
    "    shared_mem[tid] = temp;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Parallel reduction in shared memory\n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            shared_mem[tid] += shared_mem[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        atomicAdd(result, shared_mem[0]);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "dot_product= cp.RawKernel(dot_product_code, \"dot_product\")\n",
    "\n",
    "def cupy_dot(a,b):\n",
    "    n = a.shape[0]\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (n + threads_per_block - 1) // threads_per_block\n",
    "    result = cp.zeros(1, dtype=cp.float32)\n",
    "    dot_product(\n",
    "        (blocks_per_grid,), \n",
    "        (threads_per_block,), \n",
    "        (a, b, result, n)\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def torch_dot(X: torch.Tensor,Y: torch.Tensor) -> torch.Tensor:\n",
    "    if X.dim() > 1 and Y.dim() > 1:\n",
    "        return torch.sum(X*Y, dim=-1)\n",
    "    return X @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "dim = 64\n",
      "cupy: 0.04149889945983887\n",
      "torch: 0.035501956939697266\n",
      "Speedup: 0.8554915287345095\n",
      "----------\n",
      "dim = 16384\n",
      "cupy: 0.037999629974365234\n",
      "torch: 0.035997629165649414\n",
      "Speedup: 0.9473152551731061\n",
      "----------\n",
      "dim = 65536\n",
      "cupy: 0.037999868392944336\n",
      "torch: 0.036501169204711914\n",
      "Speedup: 0.9605604110852475\n",
      "----------\n",
      "dim = 262144\n",
      "cupy: 0.05249929428100586\n",
      "torch: 0.03749871253967285\n",
      "Speedup: 0.7142707926502512\n",
      "----------\n",
      "dim = 4194304\n",
      "cupy: 0.03749966621398926\n",
      "torch: 0.053003549575805664\n",
      "Speedup: 1.4134405696665289\n"
     ]
    }
   ],
   "source": [
    "compare(cupy_dot, torch_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cupy_dot(cp.array([1,2,3], dtype=cp.float32), cp.array([1,2,3], dtype=cp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_l2 = \"\"\"\n",
    "extern \"C\" __global__\n",
    "void distance(const float* x, const float* y, float* result, int n) {\n",
    "    __shared__ float shared_mem[256];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    float temp = 0;\n",
    "    while (i < n) {\n",
    "        float diff = x[i] - y[i];\n",
    "        temp += diff * diff;\n",
    "        i += blockDim.x * gridDim.x;\n",
    "    }\n",
    "    \n",
    "    shared_mem[tid] = temp;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Parallel reduction in shared memory\n",
    "    #pragma unroll\n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            shared_mem[tid] += shared_mem[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (tid == 0) {\n",
    "        atomicAdd(result, shared_mem[0]);\n",
    "        // Only one thread in the entire grid should compute the sqrt\n",
    "        __threadfence();  // Ensure all atomicAdds complete\n",
    "        if (blockIdx.x == 0 && threadIdx.x == 0) {\n",
    "            *result = sqrtf(*result);  // sqrtf for float\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "l2= cp.RawKernel(distance_l2, \"distance\")\n",
    "\n",
    "def cupy_l2(a,b):\n",
    "    n = a.shape[0]\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (n + threads_per_block - 1) // threads_per_block\n",
    "    result = cp.zeros(1, dtype=cp.float32)\n",
    "    l2(\n",
    "        (blocks_per_grid,), \n",
    "        (threads_per_block,), \n",
    "        (a, b, result, n)\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def torch_l2(X,Y):\n",
    "    return (X-Y).norm(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "print(cupy_l2(cp.array([0,1,2,3,4], dtype=cp.float32), cp.array([0,1,2,0,0], dtype=cp.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "dim = 64\n",
      "cupy: 0.03850197792053223\n",
      "torch: 0.04799962043762207\n",
      "Speedup: 1.2466793403885095\n",
      "----------\n",
      "dim = 16384\n",
      "cupy: 0.03949856758117676\n",
      "torch: 0.048999786376953125\n",
      "Speedup: 1.2405459078041154\n",
      "----------\n",
      "dim = 65536\n",
      "cupy: 0.04100179672241211\n",
      "torch: 0.05150032043457031\n",
      "Speedup: 1.256050333189901\n",
      "----------\n",
      "dim = 262144\n",
      "cupy: 0.04299807548522949\n",
      "torch: 0.05500030517578125\n",
      "Speedup: 1.2791341136808485\n",
      "----------\n",
      "dim = 4194304\n",
      "cupy: 0.038001298904418945\n",
      "torch: 0.08900141716003418\n",
      "Speedup: 2.3420625011763674\n"
     ]
    }
   ],
   "source": [
    "compare(cupy_l2, torch_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l2_batch = \"\"\"\n",
    "extern \"C\" __global__\n",
    "void batch_distance(const float* x, const float* y, float* output, const int N, const int D) {\n",
    "    extern __shared__ float shared_mem[];\n",
    "    \n",
    "    int tid = threadIdx.x;\n",
    "    int i = blockIdx.x;  // Each block handles one vector x[i]\n",
    "    int offset = i * D;  // Starting index for x[i] in memory\n",
    "    \n",
    "    float temp = 0.0f;\n",
    "    int j = tid;        // Thread-local index for vector components\n",
    "    \n",
    "    // Grid-stride loop across vector components\n",
    "    while (j < D) {\n",
    "        float diff = x[offset + j] - y[j];\n",
    "        temp += diff * diff;\n",
    "        j += blockDim.x;  // Jump by threads-per-block\n",
    "    }\n",
    "    \n",
    "    shared_mem[tid] = temp;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Parallel reduction within the block\n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            shared_mem[tid] += shared_mem[tid + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    // Write final result for this vector\n",
    "    if (tid == 0) {\n",
    "        output[i] = sqrtf(shared_mem[0]);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "l2_b= cp.RawKernel(d_l2_batch, \"batch_distance\")\n",
    "\n",
    "def cupy_l2_b(x,y):\n",
    "    N, D = x.shape\n",
    "    threads_per_block = 256  # Can experiment with 128-1024\n",
    "    blocks_per_grid = N\n",
    "    \n",
    "    # Output array (one distance per vector)\n",
    "    output = cp.zeros(N, dtype=cp.float32)\n",
    "    \n",
    "    # Calculate required shared memory (1 float per thread)\n",
    "    shared_mem_size = threads_per_block * cp.dtype(cp.float32).itemsize\n",
    "    \n",
    "    # Launch kernel\n",
    "    l2_b(\n",
    "        (blocks_per_grid,),       # One block per vector\n",
    "        (threads_per_block,),     # Threads per block\n",
    "        (x, y, output, N, D),     # Arguments\n",
    "        shared_mem=shared_mem_size\n",
    "    )\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.576986  0.4369282]\n",
      "[[0.0802488  0.40076688 0.5116273 ]\n",
      " [0.60504085 0.45253175 0.46711785]] [0.529375   0.10946937 0.7269046 ]\n"
     ]
    }
   ],
   "source": [
    "N, D = 2, 3\n",
    "x = cp.random.rand(N, D).astype(cp.float32)\n",
    "y = cp.random.rand(D).astype(cp.float32)\n",
    "\n",
    "distances = cupy_l2_b(x, y)\n",
    "print(distances)  # (10000,)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_parameters(code, params):\n",
    "    for k, v in params.items():\n",
    "        code = '#define ' + k + ' ' + str(v) + '\\n' + code\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_code = r'''\n",
    "    extern \"C\" __global__\n",
    "    void knn_topk_kernel(const float* distances, int* indices, const int K, const int N) {\n",
    "        int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "        \n",
    "        if (tid == 0) {\n",
    "            float* temp_dist = new float[N];  // Copy of the distances\n",
    "            for (int i = 0; i < N; i++) {\n",
    "                temp_dist[i] = distances[i];\n",
    "            }\n",
    "\n",
    "            for (int k = 0; k < K; k++) {\n",
    "                float min_dist = 1e10f;\n",
    "                int min_idx = -1;\n",
    "\n",
    "                for (int i = 0; i < N; i++) {\n",
    "                    if (temp_dist[i] < min_dist) {\n",
    "                        min_dist = temp_dist[i];\n",
    "                        min_idx = i;\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if (min_idx != -1) {\n",
    "                    indices[k] = min_idx;  // Store the index of the nearest neighbor\n",
    "                    temp_dist[min_idx] = 1e10f;  // Mark it as selected\n",
    "                }\n",
    "            }\n",
    "\n",
    "            delete[] temp_dist;  // Free memory\n",
    "        }\n",
    "    }\n",
    "\n",
    "    '''\n",
    "knn = cp.RawKernel(knn_code, \"knn_topk_kernel\")\n",
    "def cupy_knn(N, D, A, X, K, device=torch.device(\"cuda\")):    \n",
    "    # Step 1: Calculate the distances using the first kernel\n",
    "    distances = cp.zeros(N, dtype=cp.float32)\n",
    "    indices = cp.zeros(K, dtype=cp.int32)  # Store K nearest indices\n",
    "\n",
    "    # Configure block and grid sizes for the distance calculation kernel\n",
    "    block_size = 256\n",
    "    grid_size = (N + block_size - 1) // block_size\n",
    "    threads_per_block = 256  # Can experiment with 128-1024\n",
    "    blocks_per_grid = N\n",
    "    shared_mem_size = threads_per_block * cp.dtype(cp.float32).itemsize\n",
    "    # Run the kernel to calculate the distances\n",
    "    l2_b(\n",
    "        (blocks_per_grid,),       # One block per vector\n",
    "        (threads_per_block,),     # Threads per block\n",
    "        (A, X, distances, N, D),     # Arguments\n",
    "        shared_mem=shared_mem_size\n",
    "    )\n",
    "\n",
    "    # Step 2: Apply the second kernel to find the K nearest neighbors by distance\n",
    "    grid_size_topk = (K + block_size - 1) // block_size\n",
    "    knn((grid_size_topk,), (block_size,), (distances, indices, K, N))\n",
    "\n",
    "    return indices  # Return the indices of the K closest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cupy_optimized_kernel(N, D, A, X, K, device=torch.device(\"cuda\")):\n",
    "    kernel_code = '''\n",
    "    extern \"C\" __global__\n",
    "    void knn_kernel(const float* A, const float* X, float* distances, int N, int D) {\n",
    "        int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "        if (idx < N) {\n",
    "            float sum = 0.0f;\n",
    "            for (int d = 0; d < D; d++) {\n",
    "                float diff = A[idx * D + d] - X[d];\n",
    "                sum += diff * diff;\n",
    "            }\n",
    "            distances[idx] = sqrtf(sum);  // L2 distance\n",
    "        }\n",
    "    }\n",
    "    extern \"C\" __global__\n",
    "    void knn_topk_kernel(const float* distances, int* indices, int K, int N) {\n",
    "        int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "        \n",
    "        if (tid == 0) {  \n",
    "            float* temp_dist = new float[N];  // Copy of the distances\n",
    "            for (int i = 0; i < N; i++) {\n",
    "                temp_dist[i] = distances[i];\n",
    "            }\n",
    "\n",
    "            for (int k = 0; k < K; k++) {\n",
    "                float min_dist = 1e10f;\n",
    "                int min_idx = -1;\n",
    "\n",
    "                for (int i = 0; i < N; i++) {\n",
    "                    if (temp_dist[i] < min_dist) {\n",
    "                        min_dist = temp_dist[i];\n",
    "                        min_idx = i;\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if (min_idx != -1) {\n",
    "                    indices[k] = min_idx;  // Store the index of the nearest neighbor\n",
    "                    temp_dist[min_idx] = 1e10f;  // Mark it as selected\n",
    "                }\n",
    "            }\n",
    "\n",
    "            delete[] temp_dist;  // Free memory\n",
    "        }\n",
    "    }\n",
    "\n",
    "    '''\n",
    "    \n",
    "    mod = cp.RawModule(code=kernel_code)\n",
    "    func_knn = mod.get_function('knn_kernel')\n",
    "    func_topk = mod.get_function('knn_topk_kernel')\n",
    "\n",
    "    # Step 1: Calculate the distances using the first kernel\n",
    "    distances = cp.zeros(N, dtype=cp.float32)\n",
    "    indices = cp.zeros(K, dtype=cp.int32)  # Store K nearest indices\n",
    "\n",
    "    # Configure block and grid sizes for the distance calculation kernel\n",
    "    block_size = 256\n",
    "    grid_size = (N + block_size - 1) // block_size\n",
    "    \n",
    "    # Run the kernel to calculate the distances\n",
    "    func_knn((grid_size,), (block_size,), (A, X, distances, N, D))\n",
    "\n",
    "    # Step 2: Apply the second kernel to find the K nearest neighbors by distance\n",
    "    grid_size_topk = (K + block_size - 1) // block_size\n",
    "    func_topk((grid_size_topk,), (block_size,), (distances, indices, K, N))\n",
    "\n",
    "    return indices  # Return the indices of the K closest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 44,  4], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, D = 100,10000\n",
    "K = 3\n",
    "A = cp.random.random((N,D), dtype=cp.float32)\n",
    "X = cp.random.random((K,D), dtype=cp.float32)\n",
    "\n",
    "cupy_knn(N,D,A,X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_closest_kernel = \"\"\"\n",
    "extern \"C\" __global__\n",
    "void closest_index(const float* x, float* y, int* output, const int N, const int M, const int D) {\n",
    "    extern __shared__ char shared_mem[];\n",
    "    float* shared_dist = (float*)shared_mem;\n",
    "    int* shared_idx = (int*)(shared_dist + blockDim.x);\n",
    "\n",
    "    int tid = threadIdx.x;\n",
    "    int i = blockIdx.x;  // Each block handles one vector x[i]\n",
    "    int num_threads = blockDim.x;\n",
    "\n",
    "    float min_dist = 99999999.0;\n",
    "    int min_index = -1;\n",
    "\n",
    "    // Grid-stride loop over M y vectors\n",
    "    for (int j = tid; j < M; j += num_threads) {\n",
    "        float sum_sq = 0.0f;\n",
    "        for (int k = 0; k < D; ++k) {\n",
    "            float diff = x[i * D + k] - y[j * D + k];\n",
    "            sum_sq += diff * diff;\n",
    "        }\n",
    "        if (sum_sq < min_dist) {\n",
    "            min_dist = sum_sq;\n",
    "            min_index = j;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Store local min into shared memory\n",
    "    shared_dist[tid] = min_dist;\n",
    "    shared_idx[tid] = min_index;\n",
    "    __syncthreads();\n",
    "\n",
    "    // Parallel reduction to find the global min\n",
    "    for (int s = num_threads / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) {\n",
    "            if (shared_dist[tid + s] < shared_dist[tid]) {\n",
    "                shared_dist[tid] = shared_dist[tid + s];\n",
    "                shared_idx[tid] = shared_idx[tid + s];\n",
    "            }\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Write the result\n",
    "    if (tid == 0) {\n",
    "        output[i] = shared_idx[0];\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "closest_kernel = cp.RawKernel(l2_closest_kernel, \"closest_index\")\n",
    "\n",
    "def cupy_closest_index(x, y):\n",
    "    N, D = x.shape\n",
    "    M, D_y = y.shape\n",
    "    assert D == D_y, \"Dimensions of x and y must match\"\n",
    "    \n",
    "    threads_per_block = 256  # Use a power of two for optimal reduction\n",
    "    blocks_per_grid = N\n",
    "    \n",
    "    output = cp.zeros(N, dtype=cp.int32)\n",
    "    \n",
    "    # Calculate shared memory size: floats + ints per thread\n",
    "    shared_mem_size = (threads_per_block * cp.dtype(cp.float32).itemsize +\n",
    "                       threads_per_block * cp.dtype(cp.int32).itemsize)\n",
    "    \n",
    "    closest_kernel(\n",
    "        (blocks_per_grid,),\n",
    "        (threads_per_block,),\n",
    "        (x, y, output, N, M, D),\n",
    "        shared_mem=shared_mem_size\n",
    "    )\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 2, 1, 2, 2, 2, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2,\n",
       "       2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 0, 1, 0, 0, 2,\n",
       "       0, 2, 1, 2, 2, 0, 0, 2, 1, 1, 0, 1, 0, 1, 2, 1, 0, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 2, 1, 1, 0, 1, 0, 2, 1, 2, 2, 0, 1, 1, 0, 1, 1,\n",
       "       0, 2, 1, 0, 1, 2, 0, 1, 1, 1, 1, 2], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cupy_closest_index(A, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.08890758, 0.41564733, 0.28502268, ..., 0.7871353 , 0.12632202,\n",
       "         0.51791453],\n",
       "        [0.6050231 , 0.29184753, 0.51308817, ..., 0.25733826, 0.8296473 ,\n",
       "         0.82374144],\n",
       "        [0.62811095, 0.6549251 , 0.12396739, ..., 0.19293967, 0.45274127,\n",
       "         0.55706614]], dtype=float32),\n",
       " array([0.06871646, 0.4052225 , 0.8851587 , ..., 0.4769703 , 0.4420246 ,\n",
       "        0.53318596], dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:3], X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_knn(N,D,A,X,K):        \n",
    "    def g(A_prime): \n",
    "        def f(Y):\n",
    "            return torch_l2(X,Y)\n",
    "        distance = torch.vmap(f)(A_prime)\n",
    "        _, indices = distance.sort()\n",
    "        return indices[:K]\n",
    "    if A.shape[0] != N:\n",
    "        return torch.vmap(g)(A)\n",
    "    return g(A)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare2(fn1, fn2):\n",
    "    for n in [64,16384,65536]:\n",
    "        print(\"----------\")\n",
    "        d=1000\n",
    "        k=3\n",
    "        print(\"dim =\", d, \"n=\", n)        \n",
    "        x1= torch.rand((n,d), device=\"cuda\", dtype=torch.float32)\n",
    "        x2= torch.rand(d, device=\"cuda\", dtype=torch.float32)\n",
    "        torch_time = benchmark(fn2,n,d,x1,x2,k,func_type=\"torch\")\n",
    "        print(\"torch:\", torch_time)        \n",
    "        del x1\n",
    "        del x2\n",
    "        x1 = cp.random.random((n, d)).astype(cp.float32)\n",
    "        x2 = cp.random.random(d).astype(cp.float32)\n",
    "        cupy_time = benchmark(fn1,n,d,x1,x2,k)\n",
    "        print(\"cupy:\",cupy_time)\n",
    "        print(\"Speedup:\", torch_time/cupy_time)\n",
    "        del x1\n",
    "        del x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare3(fn1,fn2):\n",
    "    for n in [64,16384,65536]:\n",
    "        print(\"----------\")\n",
    "        d=1000\n",
    "        k=3\n",
    "        print(\"dim =\", d, \"n=\", n)\n",
    "        x1 = cp.random.random((n, d)).astype(cp.float32)\n",
    "        x2 = cp.random.random(d).astype(cp.float32)\n",
    "        cupy_time = benchmark(fn1,n,d,x1,x2,k)\n",
    "        print(\"cupy:\",cupy_time)\n",
    "        cupy_time_2 = benchmark(fn2,n,d,x1,x2,k)\n",
    "        print(\"cupy 2:\", cupy_time_2)\n",
    "        print(\"Speedup:\", cupy_time_2/cupy_time)\n",
    "        del x1\n",
    "        del x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "dim = 1000 n= 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 0.22306132316589355\n",
      "cupy: 0.0513768196105957\n",
      "Speedup: 4.34167246739988\n",
      "----------\n",
      "dim = 1000 n= 16384\n",
      "torch: 0.5670590400695801\n",
      "cupy: 0.056891441345214844\n",
      "Speedup: 9.967387477998491\n",
      "----------\n",
      "dim = 1000 n= 65536\n",
      "torch: 2.1910436153411865\n",
      "cupy: 0.05539703369140625\n",
      "Speedup: 39.55164147500344\n"
     ]
    }
   ],
   "source": [
    "compare2(cupy_knn, torch_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "dim = 1000 n= 64\n",
      "cupy: 0.052050113677978516\n",
      "cupy 2: 0.06259870529174805\n",
      "Speedup: 1.202662220471431\n",
      "----------\n",
      "dim = 1000 n= 16384\n",
      "cupy: 0.055298805236816406\n",
      "cupy 2: 0.05983686447143555\n",
      "Speedup: 1.0820643269811159\n",
      "----------\n",
      "dim = 1000 n= 65536\n",
      "cupy: 0.0556178092956543\n",
      "cupy 2: 0.058794498443603516\n",
      "Speedup: 1.0571164018895909\n"
     ]
    }
   ],
   "source": [
    "compare3(cupy_knn,knn_cupy_optimized_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cupy_kmeans(N,D,A,K, max_iters=100, tol=1e-4, random_state=None):\n",
    "    \"\"\"\n",
    "    K-Means clustering using CuPy and a custom CUDA kernel for the assignment step.\n",
    "    \n",
    "    Args:\n",
    "        data (cupy.ndarray): Input data of shape (N, D).\n",
    "        n_clusters (int): Number of clusters.\n",
    "        max_iters (int): Maximum number of iterations.\n",
    "        tol (float): Tolerance for convergence checking.\n",
    "        random_state (int): Seed for random number generation.\n",
    "    \n",
    "    Returns:\n",
    "        centroids (cupy.ndarray): Final centroids of shape (n_clusters, D).\n",
    "        assignments (cupy.ndarray): Indices of closest clusters for each data point.\n",
    "    \"\"\"\n",
    "    # Ensure data is float32 for CUDA kernel compatibility\n",
    "\n",
    "    # Initialize centroids by randomly selecting data points\n",
    "    rng = cp.random.RandomState(seed=random_state)\n",
    "    indices = rng.choice(N, size=K, replace=False)\n",
    "    centroids = A[indices].copy()\n",
    "    prev_centroids = cp.empty_like(centroids)\n",
    "    assignments = cp.zeros(N, dtype=cp.int32)\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        prev_centroids = centroids  # Save current centroids for convergence check\n",
    "        assignments = cupy_closest_index(A, centroids)\n",
    "\n",
    "        mask = cp.zeros((N, K), cp.float32)\n",
    "        mask[cp.arange(N), assignments] = 1.0\n",
    "        counts = mask.sum(axis=0)\n",
    "        sums = cp.matmul(mask.T, A)\n",
    "        new_centroids = sums/cp.expand_dims(counts, 1)\n",
    "        centroid_shift = cp.linalg.norm(new_centroids - centroids, axis=1).max()\n",
    "        if centroid_shift <= tol:\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "\n",
    "    return centroids, assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.51815706, 0.39126608, 0.4591676 , ..., 0.55887026, 0.5351173 ,\n",
       "         0.4687856 ],\n",
       "        [0.48987067, 0.4051168 , 0.45776987, ..., 0.4972301 , 0.51798433,\n",
       "         0.6031835 ],\n",
       "        [0.38664937, 0.5449114 , 0.45332503, ..., 0.537874  , 0.34532708,\n",
       "         0.52378136]], dtype=float32),\n",
       " array([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 1, 2,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 2, 0, 1, 2, 0, 0, 1, 1, 2, 0,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 2, 0, 2, 0, 0, 1, 1, 1, 2, 2, 1, 0, 0, 2,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 2, 2, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, D = 100,10000\n",
    "K = 3\n",
    "A = np.random.random((N,D))\n",
    "A_cp = cp.array(A, dtype=cp.float32)\n",
    "cupy_kmeans(N,D,A_cp,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cupy_ann(N, D, A, X, K, assignments=None, means=None):\n",
    "    if assignments is None or means is None:\n",
    "        means, assignments = cupy_kmeans(N, D, A, 5)\n",
    "    \n",
    "    # Compute distances from means to X (shape: n_means x N)\n",
    "    distances = cupy_l2_b(X, means)\n",
    "    \n",
    "    # Determine the nearest 2 means for each data point\n",
    "    nearest_k = 2\n",
    "    indices = cp.empty((N, nearest_k), dtype=cp.int32)\n",
    "    block_size = 256\n",
    "    grid_size_topk = (N + block_size - 1) // block_size\n",
    "    knn((grid_size_topk,), (block_size,), (distances, indices, nearest_k, N))\n",
    "    \n",
    "    # Create mask where assignment is one of the top 2 nearest means\n",
    "    mask = indices[assignments]\n",
    "    original_indices = cp.nonzero(mask)[0]\n",
    "    filtered = A[original_indices]\n",
    "    \n",
    "    # Compute approximate KNN on the filtered data\n",
    "    approx_knn = cupy_knn(filtered.shape[0], D, filtered, X, K)\n",
    "    \n",
    "    # Map indices back to the original dataset\n",
    "    return original_indices[approx_knn]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 96, 61])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cupy_ann(N,D,A_cp,X,K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
